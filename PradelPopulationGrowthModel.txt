
# Pradel reverse time model #

### modified code from Tenan et al. 2014 and Saracco et al. 2020 ###


###########################################################################################
# bring in salamander CMR data # 

grow<-read.csv("data/HB_Salamander_Use.csv",
               header=TRUE)
               
# change time to posixct
grow$Date <- 
  as.POSIXct(grow$Date, tz="", format="%m/%d/%Y")

# subset data for each site
grow1 <- grow %>%
  filter(Species == "GP") %>% # only include Gyro
  filter(Stream == "Bear")%>% 
  filter(Reach == "Upper")%>%
  filter(Primary != 1)%>% # excluding first 3 surveys every summer to ensure closure
  filter(Primary != 4)%>% 
  filter(Primary != 7)%>% 
  filter(Primary != 10)%>% 
  filter(Primary != 13)%>% 
  filter(Primary != 16)%>% 
  filter(Primary != 19)%>% 
  filter(Primary != 22)%>% 
  drop_na(FinalID)%>% # get rid of all NAs in ID data
  arrange(SurNum)%>% # data needs to be sorted by surnum to accurately add capture number for each ID
  mutate(Year = year(Date))

grow1 <- grow1 %>%
  dplyr::select(FinalID, Year)%>%
  mutate(detect =1)%>%
  arrange(FinalID,Year)%>% # sort by id, year to give cap number
  distinct()# remove duplicate rows, ie multiple caps of same individual in the same year


# create encounter history for all captures
cap.hist <- grow1 %>%
  group_by(FinalID)%>%
  spread(Year,detect,fill=0)

#adding in dummy 0's for years 2016 and 2017 when no surveys occurred 
cap.hist <- cap.hist %>%
  mutate(`2016` = 0)%>%
  mutate(`2017` = 0)%>%
  dplyr::select(FinalID,  `2012`, `2013`, `2014`, `2015`, 
                `2016`, `2017`, `2018`, `2019`, `2020`, `2021`)       

CH <- cap.hist[,2:11] # remove IDs for df


### derive data for the model
# e = index of the earliest observation
get.first <- function (x) min( which (x !=0))
e <- apply (CH , 1, get.first )

# l = index of the last observation
get.last <- function (x) max( which (x !=0))
l <- apply (CH , 1, get.last )

# u = number of animals observed for the first time at i
u <- as.data.frame ( table (e)) $Freq
# add in missing years
u<-c(u[1],u[2],u[3],u[4],0,0,u[5],u[6],u[7],u[8])

# n = number of animals observed at i
n <- colSums (CH)

# v = number of animals observed for the last time at i
v <- as.data.frame ( table (l)) $Freq
v<-c(v[1],v[2],v[3],v[4],0,0,v[5],v[6],v[7],v[8])

# d = number of animals removed from the population at time i
d <- rep (0, dim(CH )[2])


nyears <- length(u)

# bundle data for jags
jags.data  <- list(u=u, n=n, v=v, d=d, nyears=nyears)


##########
sink("pradel_null.txt")
cat("
data{
    C <- 10000
    zeros  <- 0
    }
    
    model {
    ###########  PRIORS  #######################
    
    gamma[ 1]  <- 0 # deterministic relation (<-)
    phi[nyears] <- 0
    
    for (t in 1:nyears){ # t = time = nyears
        # no  constraints  for mu
    mu[t] ~ dunif (0,1) # stochastic relation (~)
    }

    
    ## survival probability #
    for (t in 1:(nyears-1)){
    
    # logit  constraint  for  survival  probability (phi)
    phi[t] <- 1 / (1 + exp(-logit.phi[t])) 
    logit.phi[t] <- alpha.phi 
    
    
    ## population growth rate #
    # log  constraint  for  population  growth  rate (lambda)
    lambda[t] <- exp(log.lambda[t])
    log.lambda[t] <- alpha.lam 
    }
    
    
    ## capture probability #
    for (t in 1:4){ # only first four years 
    p[t] <- (1 / (1 + exp(-logit.p[t])))
    logit.p[t] <- alpha.p 
    }
   
    for (t in 7:10){ # last four years 
    p[t] <- (1 / (1 + exp(-logit.p[t])))
    logit.p[t] <- alpha.p 
    }
    
    p[5] <- 0 # no surveys completed these two years (included dummy 0's in CH)
    p[6] <- 0


    alpha.phi ~ dunif(-4,3) # keeps mean.phi btw 0.02 and 0.95
    # alpha.phi on prob  scale
    mean.phi  <- 1 / (1 + exp(-alpha.phi))
    
    
    alpha.lam ~ dunif(-5,1) # keeps mean.lam btw 0 and 3
    # alpha.lam on real  scale
    mean.lam  <- exp(alpha.lam) 
    
    
    alpha.p ~ dunif(-5,-0.4) # keeps mean.p btw 0.4 and 0.01
    # alpha.p on prob  scale
    mean.p <- 1 / (1 + exp(-alpha.p))


###########  LIKELIHOOD (ZERO -TRICK) ######
    zeros ~ dpois(zero.mean)
    zero.mean  <- -L + C
    L <- sum(l.num[1:nyears]) - l.denom

    ##### log -likelihood  for the  first  occasion
    l.num[1]  <- (u[1] * log(xi[1])) + (n[1] * log(p[1])) + (secondexpo [1] * log(1-p[1])) +
    (thirdexpo [1] * log(phi [1])) + (fourthexpo [1] * log(mu[1])) +
    (d[1] * log(1-mu[1])) + (fifthexpo [1] * log(1-(p[1]*(1 -mu [1])))) +
    (sixthexpo [1] * log(chi [1]))
    xi[1]  <- 1
    secondexpo_a [1]  <- sum(u[1:1])
    secondexpo_b [1]  <- 0
    secondexpo [1]  <- secondexpo_a [1] - secondexpo_b [1] - n[1]
    thirdexpo [1]  <- sum(v[2:nyears])
    fourthexpo [1]  <- n[1]-d[1]
    fifthexpo [1]  <- sum(u[2:nyears])
    sixthexpo [1]  <- v[1]-d[1]

    ##### log -likelihood  for the  last  occasion
    l.num[nyears] <- (u[nyears] * log(xi[ nyears])) + 
      (firstexpo[ nyears] * (log(phi[(nyears-1)]) - log(lambda[(nyears-1)]))) +
    (n[nyears] * log(p[1])) + (secondexpo[nyears] * log(1-p[nyears])) +
    (fourthexpo[nyears] * log(mu[nyears])) + (d[nyears] * log(1-mu[ nyears])) +
    (fifthexpo[nyears] * log(1-(p[ nyears]*(1-mu[nyears])))) +
    (sixthexpo[ nyears] * log(chi[nyears]))
    chi[nyears] <- 1
    firstexpo[nyears] <- sum(u[1:(nyears-1)])
    secondexpo_a[nyears] <- sum(u[1:nyears])
    secondexpo_b[nyears] <- sum(v[1:(nyears -1)])
    secondexpo[nyears] <- secondexpo_a[nyears] - secondexpo_b[nyears] - n[nyears]
    fourthexpo[nyears] <- n[nyears]-d[nyears]
    fifthexpo[nyears] <- 0
    sixthexpo[nyears] <- v[nyears]-d[nyears]

    #####  likelihood  from  occasion 2 to last -1
    for (i in 2:(nyears-1)) {

    l.num[i] <- (u[i] * log(xi[i])) + (firstexpo[i] * (log(phi[(i-1)]) - log(lambda[(i-1)]))) +
    (n[i] * log(p[i])) + (secondexpo[i] * log(1-p[i])) +
    (thirdexpo[i] * log(phi[i])) + (fourthexpo[i] * log(mu[i])) +

    (d[i] * log(1-mu[i])) + (fifthexpo[i] * log(1-(p[i]*(1-mu[i])))) +
    (sixthexpo[i] * log(chi[i]))
    # first  exponent

    firstexpo[i] <- sum(u[1:(i-1)])
    # second  exponent

    secondexpo_a[i] <- sum(u[1:i])

    secondexpo_b[i] <- sum(v[1:(i -1)])
    secondexpo[i] <- secondexpo_a[i] - secondexpo_b[i] - n[i]
    # third  exponent

    thirdexpo[i] <- sum(v[(i+1):nyears])
    # fourth  exponent

    fourthexpo[i] <- n[i]-d[i]
    # fifth  exponent

    fifthexpo[i] <- sum(u[(i+1):nyears])
    # sixth  exponent
 
    sixthexpo[i] <- v[i]-d[i]
    }
    #####  likelihood  denominator
    # 1st  product
 
    PROD1 [1]  <- 1
    for (j in 1:(nyears -1)){
    PROD1_tmp [1, j] <- 0
    }

    # fill  part of  PROD1_tmp
    for (i in 2:(nyears-1)) {
    for (j in i:(nyears -1)){
    PROD1_tmp[i, j] <- 0
    }
    }
    for (i in 2:nyears) {
    for (j in 1:(i -1)){
    PROD1_tmp[i,j] <- phi[j] * (1-(p[j]*(1-mu[j])))
    }
    }
    PROD1 [2]  <- PROD1_tmp [2,1]
    for (i in 3:nyears) {
    PROD1[i] <- prod(PROD1_tmp[i,1:(i-1)])
    }
    # 2nd  product

    PROD2[nyears] <- 1

    for (i in 1:(nyears-1)) {
    for (j in (i+1):nyears) {
    PROD2_tmp[i,j] <- gamma[j]
    }
    }

    # fill  part of  PROD2_tmp
    for (i in 1:(nyears-1)) {
    for (j in 1:i) {
    PROD2_tmp[i,j] <- 0
    }
    }

    PROD2[nyears-1]  <- PROD2_tmp [(nyears-1),nyears]
    for (i in 1:(nyears-2)) {
    PROD2[i] <- prod(PROD2_tmp[i,(i+1):nyears])
    }
    for (i in 1:nyears) {
    denom_base_tmp[i] <- xi[i] * PROD1[i] * PROD2[i] * p[i]
    }
   
    denom_base  <- sum(denom_base_tmp [])

    denom_expo  <- sum(u[1:nyears])

    l.denom  <- denom_expo * log(denom_base)

    #################  Define  xi and  chi
    for (i in 2:nyears) {
    xi.tmp[i] <- (1-gamma[i]) +
    (gamma[i] * ((1-p[(i-1)])/(1 -(p[(i-1)] * (1-mu[(i -1)])))) * xi[(i-1)])
    xi[i] <- max(xi.tmp[i] ,0.00001)
    }
    for (i in 1:(nyears-1)) {
    chi[i] <- (1-phi[i]) + (phi[i] * (1-p[(i+1)]) * chi[(i+1)])
    }
    #################  Gamma  as  derived  parameter
    for (i in 2:nyears) {
    gamma[i] <- phi[(i-1)] / lambda[(i-1)]
    
    f[i-1]<-phi[i-1]*((1-gamma[i])/gamma[i])
    }
    }
    ",fill = TRUE)
sink()


#  Initial  values
inits  <- function (){ list(alpha.phi = runif(1,  -5, 5),
                            alpha.lam = runif(1,  -0.5, 0.5),
                            alpha.p = runif(1,  -0.5, 0.5),
                            mu = matrix(runif(nsta*nyears, 0.9, 1), 
                                        nrow = dim(v)[1], ncol = dim(v)[2])
)}

# Parameters to monitor 
parameters  <- c("mean.phi", "lambda", 
                 "mean.lam", "p",  "mean.p",
                 "alpha.lam", "alpha.p","alpha.phi") 

# MCMC  settings
niter  <- 70000
nthin  <- 5
nburn  <- 60000
nchains  <- 3


# call jags
pradel.upbear<- R2jags::jags(data=jags.data, 
                                  inits=inits,
                                  parameters.to.save=parameters,
                                  model.file="pradel_null.txt",
                                  n.chains=nchains, 
                                  n.iter=niter, 
                                  n.burnin=nburn,
                                  n.thin=nthin)

# view model output
pradel.upbear$BUGSoutput$summary

# view traceplots
mcmcplots(pradel.upbear)


